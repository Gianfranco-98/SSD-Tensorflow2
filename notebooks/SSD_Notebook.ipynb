{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SSD_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tNfy1rX3nAR"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eE93aS6BdvS"
      },
      "source": [
        "**Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUsoajnP3ef3"
      },
      "source": [
        "!pip install tensorboardX\n",
        "!pip install --upgrade albumentations\n",
        "!pip install --upgrade opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK7HG1L_BfOH"
      },
      "source": [
        "**Personal repository**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU_NyMyhBg61"
      },
      "source": [
        "!git clone https://github.com/Gianfranco-98/SSD_Tensorflow2.git\n",
        "!mv -v SSD_Tensorflow2/* /content/\n",
        "!rm -r SSD_Tensorflow2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gBukiSTBOjm"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HCU0OLqBRSl"
      },
      "source": [
        "import time\n",
        "\n",
        "DATASET_NAME = 'VOC'\n",
        "DATASET_KEY = '07+12'\n",
        "\n",
        "start_dataset = time.time()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5vsQN9537eb"
      },
      "source": [
        "**COCO - Dataset preparing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9--i9Lzubc_t"
      },
      "source": [
        "if DATASET_NAME == 'COCO':\n",
        "\n",
        "    # Pycocotools\n",
        "    !git clone https://github.com/cocodataset/cocoapi.git\n",
        "    %cd cocoapi/PythonAPI\n",
        "    !python setup.py install\n",
        "    !make\n",
        "    %cd ../..\n",
        "\n",
        "    # Dataset\n",
        "    !mkdir data\n",
        "    %cd data\n",
        "    !mkdir COCO2017\n",
        "    %cd COCO2017\n",
        "    !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "    !unzip annotations_trainval2017.zip\n",
        "    !rm annotations_trainval2017.zip\n",
        "    %cd annotations\n",
        "    !rm captions_train2017.json captions_val2017.json person_keypoints_train2017.json person_keypoints_val2017.json\n",
        "    %cd /content\n",
        "\n",
        "    print(\"Total dataset preparing time =\", time.time() - start)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON6iYNWKqJ2O"
      },
      "source": [
        "**VOC - Dataset preparing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMq_Bj_KqJsB"
      },
      "source": [
        "if DATASET_NAME == 'VOC':\n",
        "    !mkdir data\n",
        "    %cd data\n",
        "    !mkdir tmp\n",
        "    %cd tmp\n",
        "\n",
        "    # Downloading sub-datasets\n",
        "    !wget pjreddie.com/media/files/VOCtrainval_11-May-2012.tar\n",
        "    !wget pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
        "    !wget pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\n",
        "    if DATASET_KEY == '07++12':\n",
        "        !wget pjreddie.com/media/files/VOC2012test.tar\n",
        "\n",
        "    # Extract them in tmp folder \n",
        "    !echo \"Extracting trainval2012...\"\n",
        "    !tar -xf VOCtrainval_11-May-2012.tar\n",
        "    !mv -v VOCdevkit/VOC2012 /content/data/tmp/\n",
        "    !rm -r VOCdevkit\n",
        "    !echo \"Extracting trainval2007...\"\n",
        "    !tar -xf VOCtrainval_06-Nov-2007.tar\n",
        "    !mv -v VOCdevkit/VOC2007 /content/data/tmp/\n",
        "    !rm -r VOCdevkit\n",
        "    !echo \"Extracting test2007...\"\n",
        "    !tar -xf VOCtest_06-Nov-2007.tar\n",
        "    if DATASET_KEY == '07++12':\n",
        "        !mv -v VOCdevkit/VOC2007 /content/data/tmp/\n",
        "    elif DATASET_KEY == '07+12':\n",
        "        !mv -v VOCdevkit/VOC2007 /content/data/tmp/VOC2007_Test\n",
        "    if DATASET_KEY == '07++12':\n",
        "        !echo \"Extracting test2012...\"\n",
        "        !tar -xf VOC2012test.tar\n",
        "        !mv -v VOCdevkit/VOC2012 /content/data/tmp/Test\n",
        "    !rm -r VOCdevkit\n",
        "\n",
        "    # First clean\n",
        "    !rm VOCtrainval_11-May-2012.tar\n",
        "    !rm VOCtrainval_06-Nov-2007.tar\n",
        "    !rm VOCtest_06-Nov-2007.tar\n",
        "    if DATASET_KEY == '07++12':\n",
        "        !rm VOC2012test.tar\n",
        "    %cd /content/data\n",
        "\n",
        "\n",
        "    # Python script -------------------------------------------------------------- #\n",
        "    import os\n",
        "    from tqdm import tqdm\n",
        "    import time\n",
        "    import warnings\n",
        "\n",
        "    DATASET_KEY_ = DATASET_KEY\n",
        "\n",
        "\n",
        "    # Create VOC2012 train dir\n",
        "    start = time.time()\n",
        "    os.mkdir('VOC2012')\n",
        "    os.mkdir('./VOC2012/JPEGImages')\n",
        "    os.mkdir('./VOC2012/Annotations')\n",
        "    if DATASET_KEY_ == '07++12':\n",
        "        os.mkdir('./VOC2012/Test')\n",
        "        os.mkdir('./VOC2012/Test/JPEGImages')\n",
        "        os.mkdir('./VOC2012/Test/Annotations')\n",
        "    elif DATASET_KEY_ == '07+12':\n",
        "        os.mkdir('VOC2007')\n",
        "        os.mkdir('./VOC2007/Test')\n",
        "        os.mkdir('./VOC2007/Test/JPEGImages')\n",
        "        os.mkdir('./VOC2007/Test/Annotations')\n",
        "    else:\n",
        "        raise ValueError(\"Datset key should be '07++12' or '07+12'\")\n",
        "\n",
        "    # VOC trainval2012\n",
        "    os.chdir('./tmp/VOC2012/ImageSets/Main')\n",
        "    trainval_names = open(\"trainval.txt\").read().split('\\n')[:-1]\n",
        "    trainval_imgs_2012 = [name + '.jpg' for name in trainval_names]\n",
        "    os.chdir('../../JPEGImages')\n",
        "    print(\"\\nAdding trainval2012 images...\")\n",
        "    for filename in tqdm(os.listdir()):\n",
        "        if filename in trainval_imgs_2012:\n",
        "            os.rename(filename, '../../../VOC2012/JPEGImages/' + filename)\n",
        "    print(\"\\nAdding trainval2012 annotations...\")\n",
        "    os.chdir('../Annotations')\n",
        "    trainval_anns_2012 = []\n",
        "    for filename in tqdm(os.listdir()):\n",
        "        if filename[:-4] in trainval_names:\n",
        "            trainval_anns_2012.append(filename)\n",
        "            os.rename(filename, '../../../VOC2012/Annotations/' + filename)\n",
        "    os.chdir('../../..')\n",
        "\n",
        "    # VOC trainval2007\n",
        "    os.chdir('./tmp/VOC2007/ImageSets/Main')\n",
        "    trainval_names = open(\"trainval.txt\").read().split('\\n')[:-1]\n",
        "    trainval_imgs_2007 = [name + '.jpg' for name in trainval_names]\n",
        "    os.chdir('../../JPEGImages')\n",
        "    print(\"\\nAdding trianval2007 images...\")\n",
        "    for filename in tqdm(os.listdir()):\n",
        "        if filename in trainval_imgs_2007:\n",
        "            os.rename(filename, '../../../VOC2012/JPEGImages/' + filename)\n",
        "    print(\"\\nAdding trainval2007 annotations...\")\n",
        "    os.chdir('../Annotations')\n",
        "    trainval_anns_2007 = []\n",
        "    for filename in tqdm(os.listdir()):\n",
        "        if filename[:-4] in trainval_names:\n",
        "            trainval_anns_2007.append(filename)\n",
        "            os.rename(filename, '../../../VOC2012/Annotations/' + filename)\n",
        "    os.chdir('../../..')\n",
        "\n",
        "    # VOC test 2007\n",
        "    if DATASET_KEY_ == '07++12':\n",
        "        imgs_2007_dst = '../../../VOC2012/JPEGImages/'\n",
        "        anns_2007_dst = '../../../VOC2012/Annotations/'\n",
        "    elif DATASET_KEY_ == '07+12':\n",
        "        imgs_2007_dst = '../../../VOC2007/Test/JPEGImages/'\n",
        "        anns_2007_dst = '../../../VOC2007/Test/Annotations/'\n",
        "    else:\n",
        "        # Insert alternative dataset configurations\n",
        "        imgs_2007_dst, anns_2007_dst = None, None\n",
        "    os.chdir('./tmp/VOC2007_Test/ImageSets/Main')\n",
        "    test_names = open(\"test.txt\").read().split('\\n')[:-1]\n",
        "    test_imgs_2007 = [name + '.jpg' for name in test_names]\n",
        "    os.chdir('../../JPEGImages')\n",
        "    print(\"\\nAdding test2007 images...\")\n",
        "    for filename in tqdm(os.listdir()):\n",
        "        if filename in test_imgs_2007:\n",
        "            os.rename(filename, imgs_2007_dst + filename)\n",
        "    print(\"\\nAdding test2007 annotations...\")\n",
        "    os.chdir('../Annotations')\n",
        "    test_anns_2007 = []\n",
        "    for filename in tqdm(os.listdir()):\n",
        "        if filename[:-4] in test_names:\n",
        "            test_anns_2007.append(filename)\n",
        "            os.rename(filename, anns_2007_dst + filename)\n",
        "    os.chdir('../../..')\n",
        "\n",
        "    # VOC test 2012\n",
        "    if DATASET_KEY_ == '07++12':\n",
        "        os.chdir('./tmp/Test/ImageSets/Main')\n",
        "        test_names = open(\"test.txt\").read().split('\\n')[:-1]\n",
        "        test_imgs_2012 = [name + '.jpg' for name in test_names]\n",
        "        os.chdir('../../JPEGImages')\n",
        "        print(\"\\nAdding test2012 images...\")\n",
        "        for filename in tqdm(os.listdir()):\n",
        "            if filename in test_imgs_2012:\n",
        "                os.rename(filename, '../../../VOC2012/Test/JPEGImages/' + filename)\n",
        "        warnings.warn(\"Missing Test Annotations in VOC2012\")\n",
        "        print(\"\\nAdding test2012 annotations...\")   \n",
        "        os.chdir('../Annotations')\n",
        "        test_anns_2012 = []\n",
        "        for filename in tqdm(os.listdir()):\n",
        "            if filename[:-4] in test_names:\n",
        "                test_anns_2012.append(filename)\n",
        "                os.rename(filename, '../../../VOC2012/Test/Annotations/' + filename)\n",
        "        os.chdir('../../..')\n",
        "\n",
        "    # Create train set\n",
        "    if DATASET_KEY_ == '07++12':\n",
        "        print(\"\\nCreating Train set = VOC2012 trainval + VOC2007 trainval + VOC2007 test...\")\n",
        "        train_imgs = trainval_imgs_2012 + trainval_imgs_2007 + test_imgs_2007\n",
        "        train_anns = trainval_anns_2012 + trainval_anns_2007 + test_anns_2007\n",
        "    elif DATASET_KEY_ == '07+12':\n",
        "        print(\"\\nCreating Train set = VOC2012 trainval + VOC2007 trainval...\")\n",
        "        train_imgs = trainval_imgs_2012 + trainval_imgs_2007\n",
        "        train_anns = trainval_anns_2012 + trainval_anns_2007\n",
        "    else:\n",
        "        # Insert alternative dataset configurations\n",
        "        train_imgs, train_anns = None, None\n",
        "    train_imgs.sort()\n",
        "    train_anns.sort()\n",
        "\n",
        "    # Create test set\n",
        "    if DATASET_KEY_ == '07++12':\n",
        "        print(\"Creating Test set = VOC2012 test...\")\n",
        "        test_imgs = test_imgs_2012\n",
        "        test_anns = test_anns_2012\n",
        "    elif DATASET_KEY_ == '07+12':\n",
        "        print(\"Creating Test set = VOC2007 test...\")\n",
        "        test_imgs = test_imgs_2007\n",
        "        test_anns = test_anns_2007\n",
        "    else:\n",
        "        # Insert alternative dataset configurations\n",
        "        test_imgs, test_anns = None, None\n",
        "    test_imgs.sort()\n",
        "    test_anns.sort()\n",
        "\n",
        "    print(\"Done in %f s\" % (time.time() - start))\n",
        "    # ---------------------------------------------------------------------------- #\n",
        "\n",
        "    # Second clean\n",
        "    !rm -r tmp\n",
        "    %cd /content\n",
        "\n",
        "    print(\"Total dataset preparing time =\", time.time() - start_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwdPyhW-Y6pR"
      },
      "source": [
        "##Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rocm5ASxY6d2"
      },
      "source": [
        "hyperparameters = {\n",
        "    # Files parameters\n",
        "    'DRIVE_PATH': '/content/drive/MyDrive',\n",
        "    'CHECKPOINT_DIR': '/content/drive/MyDrive/Checkpoints/VOC/10000/DIoU',\n",
        "    'CHECKPOINT_FILEPATH': '/content/drive/MyDrive/Checkpoints/VOC/10000/checkpoint',\n",
        "\n",
        "    # Network parameters\n",
        "    'BASE_WEIGHTS': 'imagenet',\n",
        "    'BASE_NAME': \"VGG16\",\n",
        "    'ASPECT_RATIOS': [[1., 2., 1/2],\n",
        "                    [1., 2., 1/2, 3., 1/3],\n",
        "                    [1., 2., 1/2, 3., 1/3],\n",
        "                    [1., 2., 1/2, 3., 1/3],\n",
        "                    [1., 2., 1/2],\n",
        "                    [1., 2., 1/2]],\n",
        "    'DEFAULT_BOXES_NUM': [4, 6, 6, 6, 4, 4],\n",
        "    'INPUT_SHAPE': (300, 300, 3),\n",
        "    'IMAGE_DIM': (300, 300),\n",
        "    'N_CHANNELS': 3,\n",
        "\n",
        "    # Learning parameters\n",
        "    'WEIGHT_DECAY': 5e-4,\n",
        "    'MOMENTUM': 0.9,\n",
        "    'ALPHA': 1,\n",
        "    'REGRESSION_TYPE': 'smooth_l1',\n",
        "\n",
        "    # Train \n",
        "    'CHECKPOINT_PERIOD': 250,\n",
        "    'PLOT_PERIOD': 500,\n",
        "    'BATCH_SIZE': 32,\n",
        "    'NUM_WORKERS': 8,\n",
        "    'LOAD_MODEL': True,\n",
        "    'TENSORBOARD_LOGS': False,\n",
        "\n",
        "    # Data augmentation\n",
        "    'IOU_THRESHOLDES': [0., 0.1, 0.3, 0.5, 0.7, 0.9],\n",
        "    'PATCHFIND_ATTEMPTS': 50,\n",
        "\n",
        "    # Inference\n",
        "    'CONFIDENCE_THRESHOLD': 0.01,\n",
        "    'JACCARD_THRESHOLD': 0.45,\n",
        "    'MAX_NMS_BOXES': 200,\n",
        "    'TOP_K_BOXES': 10,\n",
        "\n",
        "    # Dataset configuration ------------------------------------------------------ #\n",
        "    'DATASET_NAME': \"VOC\",\n",
        "    'DATASET_YEAR': \"2012\",\n",
        "    'TESTSET_YEAR': \"2007\",\n",
        "    'DATASET_KEY': \"07+12\",\n",
        "    'DATA_PATH': '/content/data/',\n",
        "    'TRAINVAL_PATH': '/content/data/VOC2012',\n",
        "    'TEST_PATH': '/content/data/VOC2007/Test',\n",
        "    'TRAIN_ANN_PATH': None,\n",
        "    'VAL_ANN_PATH': None,\n",
        "    'ANN_PATH': None,\n",
        "\n",
        "    # COCO Configuration\n",
        "    #'TRAIN_ANN_PATH': '/content/data/COCO2017/annotations/instances_train/2017.json',\n",
        "    #'VAL_ANN_PATH': '/content/data/COCO2017/annotations/instances_val/2017.json',\n",
        "    #'TEST_ANN_PATH': '/content/data/COCO2017/annotations/instances_test/2017.json',\n",
        "    #'SCALES': [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05],\n",
        "    #'LR_VALUES': [1e-3, 1e-4, 1e-5, 1e-5],\n",
        "    #'BOUNDARIES': [160000, 200000, 240000],\n",
        "    # ------------------\n",
        "    # VOC Configuration\n",
        "    'IMGS_FOLDER': 'JPEGImages',\n",
        "    'ANNS_FOLDER': 'Annotations',\n",
        "    'TRAIN_ANN_PATH': '/content/data/VOC2012/Annotations',\n",
        "    'VAL_ANN_PATH': '/content/data/VOC2007/Test/Annotations',\n",
        "    'TEST_ANN_PATH': '/content/data/VOC2007/Test/Annotations',\n",
        "    'SCALES': [0.10, 0.20, 0.37, 0.54, 0.71, 0.88, 1.05],\n",
        "    'LR_VALUES': [1e-3, 1e-4, 1e-4],\n",
        "    'BOUNDARIES': [60000, 80000],\n",
        "    # ------------------\n",
        "    'ITERATIONS': 80000\n",
        "    # ---------------------------------------------------------------------------- #\n",
        "}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI0n57D1BxMe"
      },
      "source": [
        "keys = list(hyperparameters.keys())\n",
        "with open('configuration.py', 'r') as readfile:\n",
        "    lines = readfile.readlines()\n",
        "with open('configuration.py', 'w') as writefile:\n",
        "    for k in keys:\n",
        "        if isinstance(hyperparameters[k], str):\n",
        "            writefile.write(k + \" = '\" + hyperparameters[k] + \"'\")\n",
        "        else:\n",
        "            writefile.write(k + \" = \" + str(hyperparameters[k]))\n",
        "        writefile.write(\"; \")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XVGrH6vYysV"
      },
      "source": [
        "##Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_vHP1bLYygj"
      },
      "source": [
        "# Dataset\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "# Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
        "\n",
        "# Math\n",
        "import numpy as np\n",
        "\n",
        "# Generic\n",
        "from tensorboardX import SummaryWriter\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import warnings\n",
        "import time\n",
        "import os\n",
        "\n",
        "# My files\n",
        "from ssd import SSD\n",
        "from loss import SSD_Loss\n",
        "from test import inference\n",
        "from configuration import *\n",
        "from detection_tools import *\n",
        "from image_detection import *\n",
        "from train_utilities import *\n",
        "from data.dataset import COCO_Dataset, VOC_Dataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqGDFnaNqVSp"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfUpZAuzq2zL"
      },
      "source": [
        "**Dataset initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH5YOnFpw4bD"
      },
      "source": [
        "if DATASET_NAME == \"COCO\":\n",
        "    train_coco = COCO(TRAIN_ANN_PATH)\n",
        "    val_coco = COCO(VAL_ANN_PATH)\n",
        "    test_coco = COCO(TEST_ANN_PATH)\n",
        "    dataset = COCO_Dataset(\n",
        "        train_coco,\n",
        "        val_coco,\n",
        "        test_coco\n",
        "    )\n",
        "elif DATASET_NAME == \"VOC\":\n",
        "    train_roots = load_annotations(TRAIN_ANN_PATH)\n",
        "    val_roots = load_annotations(VAL_ANN_PATH)\n",
        "    test_roots = load_annotations(TEST_ANN_PATH)\n",
        "    dataset = VOC_Dataset(\n",
        "        train_roots,\n",
        "        val_roots,\n",
        "        test_roots\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(\"Wrong or unsupported dataset. Available 'COCO' or 'VOC'\")\n",
        "dataset.show_info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAq8O812q7SN"
      },
      "source": [
        "dataloader = Dataloader(\n",
        "    dataset, \n",
        "    BATCH_SIZE\n",
        ")\n",
        "train_generator = dataloader.generate_batch(\"train\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viujn9aRrWz-"
      },
      "source": [
        "**Network initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39NQ4epYrWpG"
      },
      "source": [
        "ssd = SSD(num_classes=len(dataset.label_ids)+1, input_shape=INPUT_SHAPE)\n",
        "checkpoint = tf.train.Checkpoint(ssd)\n",
        "ssd.summary()                   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLTT7QHJk78H"
      },
      "source": [
        "**Generate default Bounding Boxes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SwrWeNuk7qM"
      },
      "source": [
        "fm_shapes = ssd.output_shape\n",
        "aspect_ratios = ASPECT_RATIOS\n",
        "scales = SCALES\n",
        "default_boxes = Image.generate_default_boxes(fm_shapes, aspect_ratios, scales)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY_TsygvL0u-"
      },
      "source": [
        "**Learning initializations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-KqfqoELz6i"
      },
      "source": [
        "learning_rate = PiecewiseConstantDecay(\n",
        "    boundaries = BOUNDARIES,\n",
        "    values = LR_VALUES\n",
        ")\n",
        "ssd_optimizer = SGD(\n",
        "    learning_rate = learning_rate,\n",
        "    momentum = MOMENTUM\n",
        ")\n",
        "ssd_loss = SSD_Loss(\n",
        "    default_boxes = default_boxes,\n",
        "    num_classes = ssd.num_classes, \n",
        "    regression_type = REGRESSION_TYPE, \n",
        "    hard_negative_ratio = 3, \n",
        "    alpha = ALPHA\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZmJO4uxhEMW"
      },
      "source": [
        "**Tensorboard Writer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJzYp3PjhEC7"
      },
      "source": [
        "if TENSORBOARD_LOGS:\n",
        "    os.chdir('/content/')\n",
        "    writer = SummaryWriter(comment = \"SSD | __\" + DATASET_NAME + DATASET_KEY + \"__\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuarZcjlrg0m"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_jy2GjZpIb-"
      },
      "source": [
        "**Mount Drive and load last train data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_3fifz2VahO"
      },
      "source": [
        "# Training informations\n",
        "last_iter = 0\n",
        "iterations = []\n",
        "mb_losses, loc_losses, conf_losses = [], [], []\n",
        "\n",
        "# Mount to save checkpoints\n",
        "drive.mount(\"/content/drive\")\n",
        "if LOAD_MODEL:\n",
        "    print(\"Loading latest train data...\")\n",
        "    ssd, iterations, mb_losses, loc_losses, conf_losses = \\\n",
        "        load_train_data(ssd, CHECKPOINT_DIR)\n",
        "    last_iter = iterations[-1]\n",
        "    if TENSORBOARD_LOGS:\n",
        "        for i in range(last_iter):\n",
        "            writer.add_scalar(\"Multibox loss\", mb_losses[i], i)\n",
        "            writer.add_scalar(\"Confidence loss\", conf_losses[i], i)\n",
        "            writer.add_scalar(\"Localization loss\", loc_losses[i], i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzxq3kyJpPvw"
      },
      "source": [
        "**Train loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WijFbNKbqT9k"
      },
      "source": [
        "for iteration in range(last_iter+1, ITERATIONS):\n",
        "\n",
        "    # Load data\n",
        "    #print(\"\\n________Train iteration %d________\" % iteration)\n",
        "    #print(\"1.1 Data loading\")\n",
        "    glob_start = time.time()\n",
        "    try:\n",
        "        train_imgs, train_labels, train_ids = next(train_generator)\n",
        "    except StopIteration:\n",
        "        train_generator = dataloader.generate_batch(\"train\")\n",
        "        train_imgs, train_labels, train_ids = next(train_generator)\n",
        "    batch_size = len(train_imgs)\n",
        "\n",
        "    # Match bounding boxes\n",
        "    #print(\" - Matching bboxes...\")\n",
        "    matched_boxes, def_labels = [], []\n",
        "    for b in range(batch_size):\n",
        "        boxes, labels = match_boxes(train_labels[b], default_boxes)\n",
        "        matched_boxes.append(boxes)\n",
        "        def_labels.append(labels)\n",
        "\n",
        "    # Predict and learn\n",
        "    #print(\"2. Learning step\")\n",
        "    input_imgs = np.stack(train_imgs, axis=0)\n",
        "    matched_boxes = tf.stack(matched_boxes, axis=0)\n",
        "    def_labels = tf.stack(def_labels, axis=0)\n",
        "    multibox_loss, localization_loss, confidence_loss = \\\n",
        "        learn(ssd, ssd_optimizer, ssd_loss, input_imgs, matched_boxes, def_labels)\n",
        "    print(\"[%d] (%f s)   -   Multibox loss = |%f|, Localization loss = |%f|, Confidence_loss = |%f|\" % \n",
        "          (iteration, time.time() - glob_start, multibox_loss, localization_loss, confidence_loss))\n",
        "    \n",
        "    # Plot train process\n",
        "    iterations.append(iteration)\n",
        "    mb_losses.append(multibox_loss)\n",
        "    loc_losses.append(localization_loss)\n",
        "    conf_losses.append(confidence_loss)\n",
        "    if iteration % PLOT_PERIOD == 0 and iteration > 0:\n",
        "        plot_train_data(iterations, mb_losses, loc_losses, conf_losses)\n",
        "\n",
        "    # Update Tensorboard Writer\n",
        "    if TENSORBOARD_LOGS:\n",
        "        writer.add_scalar(\"Multibox loss\", multibox_loss.numpy(), iteration)\n",
        "        writer.add_scalar(\"Confidence loss\", confidence_loss.numpy(), iteration)\n",
        "        writer.add_scalar(\"Localization loss\", localization_loss.numpy(), iteration)\n",
        "\n",
        "    # Save checkpoint\n",
        "    if iteration % CHECKPOINT_PERIOD == 0 and iteration > 0:\n",
        "        print(\" - Saving Train data...\")\n",
        "        save_train_data(checkpoint, CHECKPOINT_FILEPATH, iterations, mb_losses, loc_losses, conf_losses)\n",
        "\n",
        "    #print(\"___Done in %f s!___\" % (time.time() - glob_start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICGzCytfzy0_"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhhsxY4WhgH-"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
        "ssd.load_weights(latest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXURek0Nnou3"
      },
      "source": [
        "TEST_SIZE = 1\n",
        "TEST_ITERATIONS = 10\n",
        "dataloader = Dataloader(\n",
        "    dataset, \n",
        "    TEST_SIZE\n",
        ")\n",
        "test_generator = dataloader.generate_batch(\"test\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEgIpIBzzyrs"
      },
      "source": [
        "IMGS_ARRAY = []\n",
        "for iteration in range(TEST_ITERATIONS):\n",
        "\n",
        "    # Load data\n",
        "    print(\"\\n________Test iteration %d________\" % iteration)\n",
        "    print(\"1.1 Data loading\")\n",
        "    glob_start = time.time()\n",
        "    try:\n",
        "        test_imgs, test_labels, test_ids = next(test_generator)\n",
        "    except StopIteration:\n",
        "        test_generator = dataloader.generate_batch(\"test\")\n",
        "        test_imgs, test_labels, test_ids = next(test_generator)\n",
        "    batch_size = len(test_imgs)\n",
        "    IMGS_ARRAY.append(test_imgs)\n",
        "\n",
        "    # Inference\n",
        "    print(\"2. Inference\")\n",
        "    infer_time = time.time()\n",
        "    input_imgs = np.stack(test_imgs, 0)\n",
        "    vb, l, scores,  = inference(ssd, np.expand_dims(input_imgs[0], 0), default_boxes, 0.4)\n",
        "    print(\"Inference time =\", time.time() - infer_time)\n",
        "    \n",
        "    # Show ground truth image boxes\n",
        "    gt_boxes = np.stack(test_labels[0], axis=0)[..., :-1]\n",
        "    gt_labels = np.stack(test_labels[0], axis=0)[..., -1]\n",
        "    test_bboxes(test_imgs[0], gt_boxes, 'min_max', gt_labels, dataset.classnames_dict)\n",
        "\n",
        "    # Show predicted image boxes\n",
        "    if vb.shape[0] != 0:\n",
        "        test_bboxes(test_imgs[0], vb, 'min_max', l, dataset.classnames_dict, scores)\n",
        "    else:\n",
        "        print(\"No bboxes predicted\")\n",
        "    \n",
        "    print(\"___Done in %f s!___\" % (time.time() - glob_start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ajPUwgEVwrJ"
      },
      "source": [
        "**Compute mAP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhdPVv5ocph5"
      },
      "source": [
        "*Credits*: https://github.com/Cartucho/mAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04z1eNgeVwhd"
      },
      "source": [
        "# 1. Clone repository\n",
        "!git clone https://github.com/Cartucho/mAP\n",
        "for f in tqdm(os.listdir('./mAP/input/ground-truth')):\n",
        "    filename = './mAP/input/ground-truth/' + f\n",
        "    !rm $filename\n",
        "for f in tqdm(os.listdir('./mAP/input/detection-results')):\n",
        "    filename = './mAP/input/detection-results/' + f\n",
        "    !rm $filename\n",
        "\n",
        "# 2. Convert labels\n",
        "for i in tqdm(range(len(dataset.test_ids))):\n",
        "\n",
        "    # Load data\n",
        "    try:\n",
        "        test_imgs, test_labels, test_ids = next(test_generator)\n",
        "    except StopIteration:\n",
        "        test_generator = dataloader.generate_batch(\"test\")\n",
        "        test_imgs, test_labels, test_ids = next(test_generator)\n",
        "\n",
        "    # Inference\n",
        "    input_imgs = np.stack(test_imgs, 0)\n",
        "    vb, l, scores = inference(ssd, np.expand_dims(input_imgs[0], 0), default_boxes, 0.3)\n",
        "    if vb.shape[0] > 0:\n",
        "        if np.max(vb) <= 1.5:\n",
        "            vb = np.clip(vb, 0, 1)\n",
        "            vb[..., 0] = vb[..., 0] * input_imgs[0].shape[1]\n",
        "            vb[..., 1] = vb[..., 1] * input_imgs[0].shape[0]\n",
        "            vb[..., 2] = vb[..., 2] * input_imgs[0].shape[1]\n",
        "            vb[..., 3] = vb[..., 3] * input_imgs[0].shape[0]\n",
        "        vb = np.array(vb, dtype=np.int32)\n",
        "      \n",
        "    # Get ground truth image boxes\n",
        "    gt_boxes = np.stack(test_labels[0], axis=0)[..., :-1]\n",
        "    gt_labels = np.stack(test_labels[0], axis=0)[..., -1]\n",
        "    if np.max(gt_boxes) <= 1.5:\n",
        "        gt_boxes = np.clip(gt_boxes, 0, 1)\n",
        "        gt_boxes[..., 0] = gt_boxes[..., 0] * input_imgs[0].shape[1]\n",
        "        gt_boxes[..., 1] = gt_boxes[..., 1] * input_imgs[0].shape[0]\n",
        "        gt_boxes[..., 2] = gt_boxes[..., 2] * input_imgs[0].shape[1]\n",
        "        gt_boxes[..., 3] = gt_boxes[..., 3] * input_imgs[0].shape[0]\n",
        "    gt_boxes = np.array(gt_boxes, dtype=np.int32)        \n",
        "\n",
        "    # Create the files\n",
        "    name = test_ids[0] + '.txt'\n",
        "    ## 1. GT\n",
        "    with open(name, 'w') as writefile:\n",
        "        lines = []\n",
        "        for j in range(len(gt_labels)):\n",
        "            b = gt_boxes[j]\n",
        "            char = \"\" if j == 0 else \"\\n\"\n",
        "            lines.append(char + dataset.classnames_dict[gt_labels[j]] + \" \" + str(b[0]) + \" \" + str(b[1]) + \" \" + str(b[2]) + \" \" + str(b[3]))\n",
        "        writefile.writelines(lines)\n",
        "    os.rename(name, './mAP/input/ground-truth/' + name)\n",
        "    ## 2. Pred\n",
        "    with open(name, 'w') as writefile:\n",
        "        if vb.shape[0] > 0:\n",
        "            lines = []\n",
        "            for j in range(len(l)):\n",
        "                b = vb[j]\n",
        "                char = \"\" if j == 0 else \"\\n\"\n",
        "                lines.append(char + dataset.classnames_dict[l[j]] + \" \" + str(scores[j]) + \" \" + str(b[0]) + \" \" + str(b[1]) + \" \" + str(b[2]) + \" \" + str(b[3]))\n",
        "            writefile.writelines(lines)\n",
        "    os.rename(name, './mAP/input/detection-results/' + name)\n",
        "\n",
        "# 3. Compute mAP\n",
        "%cd /content/mAP/\n",
        "!python main.py -na"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlvUgjnbCuKo"
      },
      "source": [
        "**Test with specific images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK4lh405CddJ"
      },
      "source": [
        "imgs = os.listdir('/content/data/VOC2007/Test/JPEGImages')[0:32]\n",
        "for i in range(len(imgs)):\n",
        "    imgs[i] = cv2.resize(cv2.imread(imgs[i]), (300, 300))\n",
        "img = imgs[10]\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "725esKs2Cf0d"
      },
      "source": [
        "vb, l, scores = inference(\n",
        "                          ssd, \n",
        "                          np.expand_dims(preprocess_input(img), 0), \n",
        "                          default_boxes, \n",
        "                          conf_threshold=0.3,\n",
        "                          loc_threshold=0.45,\n",
        "                          num_nms_output=250,\n",
        "                          top_k=10\n",
        ")\n",
        "\n",
        "# Show predicted image boxes\n",
        "test_bboxes(img, vb, l, dataset.classnames_dict, scores)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}